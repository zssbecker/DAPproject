채점하시는 분들께 도움을 드리기 위해 ReadMe를 작성합니다.

== 첨부파일 목록 ==
1. data 디렉터리에는 분석할 데이터들이 담겨있습니다. 해당 디렉토리 내부에 있는 ReadMe를 확인해주세요.

2. font 디렉터리에는 그래프에 사용한 폰트가 담겨있습니다. 해당 디렉터리 내부에 있는 ReadMe를 확인해주세요.

3. ipynb 디렉터리에는 ipynb 파일들이 들어있습니다. 채점을 할 파이썬 파일들은 이곳에 모두 담겨있습니다.

4. presentation은 발표에 사용한 ppt입니다. 
   .key형식의 경우 Mac에서 사용할 수 있습니다.
   .pptx형식의 경우 Window에서 사용할 수 있습니다. (Mac에서 변환한 것으로 충돌이 발생할 수 있습니다.)


== 차용 예제, 자료 목록 ==

DAP_project와 관련하여 차용한 자료는 다음과 같습니다.
1. konlpy 공식 사이트) https://konlpy.org/ko/latest/
   Konlpy와 관련한 전반적인 메소드 사용법을 이곳에서 숙지했습니다. 
   
2. 텍스트 분류와 감성(Sentiment)분석 구현하기) https://techblog-history-younghunjo1.tistory.com/111
   Bow 벡터, TF-IDF 분석의 전반적인 사용법을 이곳에서 차용했습니다.
   
3. Konlpy를 이용해서 영화 리뷰 분석하기) https://cyc1am3n.github.io/2018/11/10/classifying_korean_movie_review.html
   Konlpy의 실제 사용 예제, 그리고 단어 빈도수를 그래프로 표현하는 것을 이곳에서 아이디어를 따왔습니다.

4. 딥러닝을 위한 자연어처리 입문) https://wikidocs.net/21694
   자연어처리에 대한 전반적인 진행, 해당 프로젝트에 사용된 모든 코드의 근간이 되는 예제입니다.

5. 호텔 리뷰 자연어처리 입문) https://hyemin-kim.github.io/2020/08/29/E-Python-TextMining-2/#3-4-word-count
   이것도 마찬가지로 해당 프로젝트에 사용된 모든 코드의 근간이 되는 예제입니다.
   
6. 자연어처리 바이블) 참고한 서적입니다.
   자연어처리에 대한 기본적인 이해와 원리에 대해 공부할 수 있었습니다.

webCrawler와 관련하여 차용한 자료는 다음과 같습니다.
1. 파이썬 웹크롤링) https://rubber-tree.tistory.com/88
